{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import helper\n",
    "\n",
    "from pandas import read_excel, DataFrame, merge\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = read_excel(\"boston.xlsx\")\n",
    "boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>CAT. MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  CAT. MEDV  \n",
       "0  396.90   4.98  24.0          0  \n",
       "1  396.90   9.14  21.6          0  \n",
       "2  392.83   4.03  34.7          1  \n",
       "3  394.63   2.94  33.4          1  \n",
       "4  396.90   5.33  36.2          1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df = DataFrame(boston,columns=boston.columns)\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM',\n",
       " 'ZN',\n",
       " 'INDUS',\n",
       " 'CHAS',\n",
       " 'NOX',\n",
       " 'RM',\n",
       " 'AGE',\n",
       " 'DIS',\n",
       " 'RAD',\n",
       " 'TAX',\n",
       " 'PTRATIO',\n",
       " 'B',\n",
       " 'LSTAT',\n",
       " 'MEDV',\n",
       " 'CAT. MEDV']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(boston_df.columns)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score # 성능 측정 평가 지표 \n",
    "\n",
    "# x,y 분할\n",
    "y = boston_df[\"PRICE\"]\n",
    "x = boston_df.drop(['PRICE'],axis = 1, inplace = False)\n",
    "\n",
    "# 훈련용 데이터와 평가용 데이터 분할하기\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state = 156)\n",
    "\n",
    "# 선형회귀 분석 모델 생성 \n",
    "lr = LinearRegression()\n",
    "\n",
    "# 선형회귀 분석 : 모델 훈련 (학습데이터를 가지고 수행)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#선형회귀 분석 : 평가데이터(x_test) 에 대한 예측 후생 -> 예측 결과 y_predict 구하기 \n",
    "y_predict = lr.predict(x_test)\n",
    "\n",
    "\n",
    "# 선형회귀 분석 모델을 평가지표를 통해 평가하고 회귀 계수를 확인하여 피처의 영향을 분석한다.\n",
    "\n",
    "mse = mean_squared_error(y_test,y_predict)\n",
    "rmse = np.sqrt(mse)\n",
    "print('mse:{0:.3f}, RMSE:{1:.3f}'.format(mse,rmse))\n",
    "print('R^2(Variance score) : {0:.3f}'.format(r2_score(y_test,y_predict)))\n",
    "\n",
    "# 회귀 분석은 지도 학습이므로 평가 데이터 x 에 대한 결과값 y를 이미 알고 있는 상태에서 평가 데이터 y_test와 위에서 구한 예측 결과 y_predict의 오차를 계산하여 모델을 평가한다. 평가 지표 MSE를 구하고 구한 값의 제곱근을 계산하여 모델을 평가한다. 평가 지표 MSE를 구하고 구한 값의 제곱근을 계산하여 np.sqrt 평가 지표 RMSE를 구한다. 그리고 평가 지표 R2를 구한다 (r2_score)\n",
    "\n",
    "print('y 절편 값:',lr.intercept_)\n",
    "print('회귀 계수 값 : ',np.round(lr.coef_,1))\n",
    "\n",
    "# 선형회귀의 y절편과 각 피처의 회귀 계수를 확인한다. \n",
    "\n",
    "coef = Series(data=np.round(lr.coef_,2),index = x.colums)\n",
    "coef.sort_values(ascending=False)\n",
    "# 회귀 모델에서 구한 회귀 계수 값 lr.coef_과 피처 이름x.coulums를 묶어서 시리즈 자료형으로 만들고, 회귀 계수 값을 기준으로 내림차순으로 정렬하여 ascending 확인한다. \n",
    "\n",
    "\n",
    "# 회귀 분석 결과를 산점도 + 선형 회귀 그래프로 시각화 하기\n",
    "\n",
    "import matplotilb.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axs = plt.subplots(figsize = (16,16), ncols = 3, nrows=5)\n",
    "x_features = ['CRIM',\n",
    " 'ZN',\n",
    " 'INDUS',\n",
    " 'CHAS',\n",
    " 'NOX',\n",
    " 'RM',\n",
    " 'AGE',\n",
    " 'DIS',\n",
    " 'RAD',\n",
    " 'TAX',\n",
    " 'PTRATIO',\n",
    " 'B',\n",
    " 'LSTAT'] # list(boston_df.columns)\n",
    "\n",
    "for i, feature in enumerate(x_features) : \n",
    "    row = int(i/3)\n",
    "    col = i%3\n",
    "    sb.regplot(x=feature, y='PRICE', data = boston_df, ax = axs[row][col])\n",
    "\n",
    "# 독립 변수인 13개 피처와 종속 변수인 주택 가격 PRICE와의 회귀관계를 보여주는 13개 그래프를 subplots()를 사용하여 5행 3열 구조로 모아서 나타낸다.\n",
    "# seaborn의 regplot()은 산점도 그래프와 선형 회귀 그래프를 함께 그려준다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀 분석\n",
    "\n",
    "로지스틱 회귀는 분류에 사용하는 기법으로 선형 함수를 사용하여 추세를 예측하는 선형 회귀와 달리 s 자 함수를 사용하여 참(1) 거짓(0)을 분류한다.\n",
    "\n",
    "시그모이드 함수 : 로지스틱 회귀에서 사용하는 s자 함수. \n",
    "시드모이드 함수는 x의 값이 커지면 y의 값은 1에 근사하게 되고 x의 값이 작아지면 y의 값은 0에 근사하게 되어 s자 형태의 그래프가 된다. \n",
    "이진 분류에 많이 사용된다.\n",
    "\n",
    "로지스틱 회귀 모델의 성능 평가 지표는 이진 분류 결과를 평가하기 위해 오차 행렬에 기반한 성능 지표인 정밀도(예측이 Positive중 참인 비율), 재현율(실제가 positive중 참), f1 스코어(정밀도와 재현율 결합), ROC_AUC(오차행렬의 FP Rate가 변할 때 TP Rate가 어떻게 변하는지 나타내는 곡선) 1에 가까울수록 좋다)를 사용한다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유방암 진단 데이터셋\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "b_cancer  = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  diagnosis  \n",
       "0          0.4601                  0.11890          0  \n",
       "1          0.2750                  0.08902          0  \n",
       "2          0.3613                  0.08758          0  \n",
       "3          0.6638                  0.17300          0  \n",
       "4          0.2364                  0.07678          0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_cancer.DESCR # 데이터 셋에 대한 설명 확인 \n",
    "b_cancer_df = pd.DataFrame(b_cancer.data, columns = b_cancer.feature_names)\n",
    "# 데이터셋 객체의 datㅁ 배열 b_cancer.data 즉 독립변수 x가 되는 피처를 dataFrame 자료형으로 변환하여 b_cancer_df 생성\n",
    "b_cancer_df['diagnosis'] = b_cancer.target\n",
    "# 유방암 유무 class로 사용할 diagnosis 컬럼을 b_cancer_df에 추가하고 데이터셋 객체의 ㅅarget 컬럼 b_cancer.target 저장한다\n",
    "b_cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  diagnosis  \n",
       "0                  0.2654          0.4601                  0.11890          0  \n",
       "1                  0.1860          0.2750                  0.08902          0  \n",
       "2                  0.2430          0.3613                  0.08758          0  \n",
       "3                  0.2575          0.6638                  0.17300          0  \n",
       "4                  0.1625          0.2364                  0.07678          0  \n",
       "..                    ...             ...                      ...        ...  \n",
       "564                0.2216          0.2060                  0.07115          0  \n",
       "565                0.1628          0.2572                  0.06637          0  \n",
       "566                0.1418          0.2218                  0.07820          0  \n",
       "567                0.2650          0.4087                  0.12400          0  \n",
       "568                0.0000          0.2871                  0.07039          1  \n",
       "\n",
       "[569 rows x 31 columns]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 크기 (데이터 샘플, 열 갯수)\n",
    "b_cancer_df.shape \n",
    "b_cancer_df.info # 정보 확인 악성이면 1 양성이면 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀 분석의 피처로 사용할 데이터를 평균이 0 분산이 1이 되는 정규 분포 형태로 맞춘다. \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler\n",
    "\n",
    "b_cancer_scaled = scaler.fit_transform(b_cancer.data)# 피처로 사용할 데이터에 대해 정규 분포 스케일링을 수행하여 저장한다. \n",
    "print(b_cancer.data[0]) \n",
    "print(b_cancer_scaled[0]) # 값이 조정된거 확인 \n",
    "\n",
    "\n",
    "# 로지스틱 회귀를 이용하여 분석 모델 구축하기 \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# x,y 설정하기 \n",
    "y = b_cancer_df['diagnosis']\n",
    "x = b_cancer_scaled # 정규 분포로 스케일링 \n",
    "\n",
    "# 훈련용 데이터와 평가용 데이터 분할하기\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state = 0)\n",
    "\n",
    "# 로지스틱 회귀 분석 : 모델 객체 생성\n",
    "lr_b_cancer = LogisticRegression() \n",
    "\n",
    "# 로지스틱 회귀 분석 : 모델 훈련 학습 데이터로 모델 학습을 수행(fit)한다.\n",
    "lr_b_cancer.fit(x_train, y_train)\n",
    "\n",
    "# 로지스틱 회귀 분석 평가 데이터에 대한 예측 수행. x_test를 가지고 예측을 수행predict 수행하여 예측값 y_predict를 구한다)\n",
    "y_predict = lr_b_cancer.predict(x_test)\n",
    "\n",
    "# 생성한 모델의 성능 확인하기\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score \n",
    "# 평가 지수 계산을 제공하는 모듈 임포트\n",
    "\n",
    "# 오차 행렬\n",
    "# 평가를 위해 7:3으로 분할한 test데이터에 대해 이진 분류의 성능 평가 기본이 되는 오차 행렬을 구한다. \n",
    "confusion_matrix(y_test,y_predict)\n",
    "\n",
    "# 성능 평가 지표인 정확도, 정밀도, 재현율, F1스코어, ROC-AUC 스코어를 구한다.\n",
    "accuracy = accuracy_score(y_test,y_predict)\n",
    "precision = precision_score(y_test,y_predict)\n",
    "recall = recall_score(y_test,y_predict)\n",
    "f1 = f1_score(y_test,y_predict)\n",
    "roc_auc = roc_auc_score(y_test,y_predict)\n",
    "print('정확도:{},정밀도:{},재현율:{},F1:{}'.format(accuracy,precision,recall,f1))\n",
    "\n",
    "print('ROC_AUC:',roc_auc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
